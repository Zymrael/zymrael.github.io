<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Self.">
  <meta name="keywords" content="Neural Implicit Representations, Fractals, Compression, Deep Generative Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Self-Similarity Priors: Neural Collages as Differentiable Fractal Representations</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
    <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://zymrael.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-size-3 publication-title">Self-Similarity Priors: <br/> Neural Collages as Differentiable Fractal Representations</h1>
          <div class="is-size-6 publication-authors">
            <span class="author-block">
              <a href="https://zymrael.github.io/">Michael Poli*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://winniexu.ca/">Winnie Xu*</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://massastrello.github.io/">Stefano Massaroli*</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://cs.stanford.edu/~chenlin/">Chenlin Meng</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="">Kuno Kim</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://cs.stanford.edu/~ermon/">Stefano Ermon</a><sup>1</sup>
            </span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>Stanford University, </span>
            <span class="author-block"><sup>2</sup>University of Toronto, </span>
            <span class="author-block"><sup>3</sup>University of Tokyo, </span>
            <span class="author-block"><sup>*</sup>Equal contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2204.07673#:~:text=Self%2DSimilarity%20Priors%3A%20Neural%20Collages%20as%20Differentiable%20Fractal%20Representations,-Michael%20Poli%2C%20Winnie&text=Many%20patterns%20in%20nature%20exhibit,described%20via%20self%2Dreferential%20transformations."
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ermongroup/self-similarity-prior"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Blog / TUtorial Link-->
              <span class="link-block">
                <a href="zymrael.github.io/blog/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-newspaper"></i>
                  </span>
                  <span>Blog</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h4 class="content has-text-centered is-size-12">
        Representing <span class="deolive">data</span> as the <span class="dewine">parameters</span> of an iterative map: the <span class="deblue">collage operator</span>.
      </h4>
      <video id="" controls autoplay muted loop playsinline>
        <source src="./assets/CollageSteps.mp4" type="video/mp4">
      </video>
      <!-- lazy way to add spacing -->
      <h2>
        <br>
        <br>
      </h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-five-fifths">
        <h3 class="content has-text-justified is-size-12">
            <p>
            <b>Intuition:</b> Data can be represented in a variety of ways. In the original space, 
            via a collection of values (for example, pixels), as a set of coefficients and bases functions (for example, Fourier coefficients and complex exponentials), or 
            implicitly via the parameters of a map (for example, pixel locations to pixel values). Each method has advantages and disadvantages. 
          </p>

          <p>
            We investigate an alternative approach, which involves two steps: 
            <br>
            (1) Selection of a family of iterated, parametrized functions. We consider collage operators, a class of maps that require few parameters compared to data dimensionality, and that can capture self-similarity 
            by relating two partitions of the data space (patches for images). 
            <br>
            (2) Given a data point, or a dataset, train an encoder produce the corresponding collage parameters. A <b>Neural Collage</b> is comprised of both neural network encoder as well as collage operator as decoder.
            <br>
            We show how a collage parameter representation obtained via Neural Collages can be used in machine learning tasks:
          </p>
        </h3>
        </div>
      </div>
      <img src="./assets/diagram.svg", 
      alt="Applications of Neural Collage Operators">
      </div>
     </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
        <h2 class="title is-3 has-text-centered">Summary</h2>

        <div class="content has-text-justified">
          <p>
            Many patterns in nature exhibit self–similarity: they can be efficiently described via self–referential
            transformations. This property is common in natural and artificial objects, such as molecules,
            shorelines, galaxies and even images. This work develops a method to learn representations of data designed to maximally leverage self-similarity, both across regions of a single sample as well as across datasets.
          </p>
          <p>
            To this end, we propose to represent data as the parameters of a contractive, iterative map defined on partitions of data space: the collage operator. Instead of performing extensive search for the set of parameters corresponding
            to each data sample, we use a neural network encoder to amortize the cost to a single forward pass. We refer to the encoder and collage operator together as a Neural Collage.
            
            <!-- We show thow such a representation is capable of capturing the self-similarity across data points, yielding.
            
            To this end, we design
            a novel class of implicit operators, Neural Collages, which (1) represent data as the parameters of
            a self–referential, structured transformation, and (2) employ hypernetworks to amortize the cost of
            finding these parameters to a single forward pass.  -->
          </p>
          <p>
            We investigate how to leverage the compact representations produced by Neural Collages in various tasks, including data compression and generation.
            Neural Collage are orders of magnitude faster than self–similarity–based
            image compression algorithms during encoding and offer compression rates competitive with other neural implicit methods. Finally,
            we showcase applications of Neural Collages as deep generative models and as a method to produce fractal art.
          </p>
      </div>
    </div>
  </section>

  <section class="core">
    <div class="container is-max-desktop has-text-centered">
      <h4 class="title is-4">Collage step in code</h4>
      <div class="content has-text-justified">
      <pre><code class="python">    def collage_operator(self, z, collage_weight, collage_bias):
        """Collage Operator (decoding). Performs the steps described in  Def. 3.1, Figure 2."""
    
        # Split the current iterate `z` into source patches according to the partitioning scheme.
        domains = img_to_patches(z)
    
        # Pool domains (pre augmentation) to range patch sizes.
        pooled_domains = self.pool(domains) 
    
        # If needed, produce additional candidate source patches as augmentations of existing domains.
        # Auxiliary learned feature maps / patches are also introduced here.
        if self.n_aug_transforms > 1:
            pooled_domains = self.generate_candidates(pooled_domains)
    
        pooled_domains = repeat(pooled_domains, 'b c d h w -> b c d r h w', r=self.num_ranges)
    
        # Apply the affine maps to source patches
        range_domains = torch.einsum('bcdrhw, bcdr -> bcrhw', pooled_domains, collage_weight)
        range_domains = range_domains + collage_bias[:, :, :, None, None]
    
        # Reconstruct data by "composing" the output patches back together (collage!).
        z = patches_to_img(range_domains)
    
        return z</code></pre>
        <h4 class="title is-5">Partitions</h4> 

        <h4 class="title is-4">Collage operator properties</h4>
        <h4 class="title is-5">One set of parameters, one data point</h4> 
        <h4 class="title is-5">Short parametrization</h4> 
        <h4 class="title is-5">Resolution independent</h4> 
        <h4 class="title is-5">Collage theorem</h4> 
        <div class="content has-text-justified">
          Collage operators 
        </div>
    </div>
  </section>

  <section class="fin">
    <div class="container is-max-desktop has-text-centered">
        <h4 class="title is-3">Examples</h4> 
        <h4 class="title is-4">Neural Collages as Generative Models</h4> 
        <div class="content has-text-justified">
          <p>
          We train deep generative models (VDVAEs) with collage parameters as latent variables. The ELBO is calculated on the images decoded through the collage operator, given a sample of collage parameters. 
          Collage parameter representations are "rate efficient" and generally significantly smaller than data dimensionality, resulting generative models that are easier to optimize.
        </p>
          <p>
          Regardless of the image size used during training, introducing Neural Collages in a generative model allows for sampling at arbitrary resolution. Note that the details introduced
          by the upsampling depend on the type of collage operator, for example augmentation transforms used to produce auxiliary patches from domain patches at each iteration. 
        </p>
        </div>
        <div class="columns is-centered has-text-centered">

          <div class="column is-two-fourths">
            <div class="content has-text-justified">
              Binarized MNIST samples from a Collage VDVAE decoded at the standard resolution (28x28).
            </div>
          <image src="./assets/1x_superres.png" alt="Collage as Generative Model">     
          </div>
          <div class="column is-two-fourths">
            <div class="content has-text-justified">
            Binarized MNIST samples from a Collage VDVAE decoded at 40x the resolution (1440x1440).
          </div>
          <image src="./assets/40x_superres_vdcvae.png" alt="Collage as Generative Model">     
        </div>

        </div>
    <h4 class="title is-4">Neural Collages as Image Compressors</h4> 
    <section class="hero is-light is-small">
      <div class="hero-body">
        <div class="container">
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item">
              <image src="./assets/source1.png" alt="Collage as Image Compressor">
              </video>
            </div>
            <div class="item item">
              <image src="./assets/fc1.png" alt="Collage as Image Compressor">
              </video>
            </div>
            <div class="item item">
              <image src="./assets/coin1.png" alt="Collage as Image Compressor">
              </video>
            </div>
            <div class="item item">
              <image src="./assets/nc1.png" alt="Collage as Image Compressor">
              </video>
            </div>
              <div class="item item">
                <image src="./assets/source2.png" alt="Collage as Image Compressor">
                </video>
              </div>
              <div class="item item">
                <image src="./assets/fc2.png" alt="Collage as Image Compressor">
                </video>
              </div>
              <div class="item item">
                <image src="./assets/coin2.png" alt="Collage as Image Compressor">
                </video>
              </div>
              <div class="item item">
                <image src="./assets/nc2.png" alt="Collage as Image Compressor">
                </video>
            </div>            
          </div>
        </div>
      </div>
    </section>
    <h4 class="title is-4">More applications</h4>
        <div class="content has-text-justified">
          <p>
          Neural Collages can fractalize images. To obtain this effect, train a restricted Neural Collage without source domain partitioning on a reconstruction objective i.e., with the only source domain being the entire image.
          Fractalizing (including training) takes less than 20 seconds on a single GPU. Follow the notebook tutorial for more details!  
        </p>
          <p>
            No author was harmed in the making of these animations.
          </p>
      <section class="hero is-light">
        <div class="hero-body">
          <div class="container">
            <div id="results-carousel" class="carousel results-carousel">
              <div class="item item2">
                <video id="" autoplay muted loop playsinline, height="100%">
                  <source src="./assets/michael_zoom_small.mp4" type="video/mp4">
                </video>
              </div>
              <div class="item item">
                <video id="" autoplay muted loop playsinline, height="100%">
                  <source src="./assets/winnie_zoom_small.mp4" type="video/mp4">
                </video>
              </div>
              <div class="item item">
                <video id="" autoplay muted loop playsinline, height="100%">
                  <source src="./assets/massa_zoom_small.mp4" type="video/mp4">
                </video>
              </div>
              <div class="item item">
                <video id="" autoplay muted loop playsinline, height="100%">
                  <source src="./assets/chenlin_zoom_small.mp4" type="video/mp4">
                </video>
              </div>
                <div class="item item">
                  <video id="" autoplay muted loop playsinline, height="100%">
                    <source src="./assets/kuno_zoom_small.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="item item">
                  <video id="" autoplay muted loop playsinline, height="100%">
                    <source src="./assets/stefano_zoom_small.mp4" type="video/mp4">
                  </video>
                </div>
              </div>            
            </div>
          </div>
        </section>
        </div>

    <div class="content has-text-justified">
      <p>
        There are a number of downstream applications and questions left open for further investigation. We are looking into improved partitioning schemes, alternative data modalities,
        training deep models directly on collage representations extracted via a Neural Collages, and ways to control the type of detail introduced when upsampling via choosing appropriate transforms.
      </p>
    </div>

    <h4 class="title is-4">For experts of fractal compression</h4>
    <div class="columns is-centered">
      <div class="column has-text-justified is-5">
        <p>
      Neural Collages are inspired by Partitioned Iterated Function Systems (PIFS), the backbone of fractal compression schemes. Our official implementation includes a GPU-accelerated version of the PIFS algorithm (without quadtrees), used
      as a baseline in the image compression experiment. The main paper reports a detailed account of the history of fractal compression and its main variants.
    </p>
    </br>
    <p>
      And yes, Neural Collages can be applied to point clouds (as the first IFSs of Barnsley et al.) to produce "true" fractals!
    </p>
    </div>
    <div class="column has-text-justified is-4">
      <video id="" autoplay muted loop playsinline height="100%">
        <source src="./assets/a.mp4"
                type="video/mp4">
    </div>
  </div>
  </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              The format of this website is borrowed from the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project website.
            </p>
            <p>
              This website is licensed under a <a rel="license"
                                                  href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a
                href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
